{
  "best": {
    "name": "logreg",
    "metrics": {
      "accuracy": 0.3488372093023256,
      "precision": 0.37080954472258815,
      "recall": 0.35805860805860806,
      "f1": 0.34296296296296297
    },
    "params": {
      "C": 31.509875742000492,
      "solver": "lbfgs",
      "penalty": "l2"
    }
  },
  "all": {
    "logreg": {
      "metrics": {
        "accuracy": 0.3488372093023256,
        "precision": 0.37080954472258815,
        "recall": 0.35805860805860806,
        "f1": 0.34296296296296297
      },
      "params": {
        "C": 31.509875742000492,
        "solver": "lbfgs",
        "penalty": "l2"
      }
    },
    "rf": {
      "metrics": {
        "accuracy": 0.16279069767441862,
        "precision": 0.167420814479638,
        "recall": 0.1614010989010989,
        "f1": 0.16279267773520645
      },
      "params": {
        "n_estimators": 356,
        "max_depth": 8,
        "min_samples_split": 2,
        "min_samples_leaf": 1,
        "max_features": null
      }
    },
    "gb": {
      "metrics": {
        "accuracy": 0.20930232558139536,
        "precision": 0.20308972073677956,
        "recall": 0.211996336996337,
        "f1": 0.20452864538886043
      },
      "params": {
        "n_estimators": 263,
        "learning_rate": 0.05065050450037643,
        "max_depth": 5,
        "subsample": 0.86460442212007
      }
    },
    "voting": {
      "metrics": {
        "accuracy": 0.20930232558139536,
        "precision": 0.21388888888888888,
        "recall": 0.20902014652014653,
        "f1": 0.20935960591133007
      },
      "params": {
        "estimators": "logreg+rf+gb"
      }
    }
  },
  "timestamp": "2025-08-30T18:35:28.451589"
}